# Market Scrapper


Bombardeados de n√≥ticias, ficamos cegos para a verdade.

Este projeto nasceu da ideia de **automatizar a coleta e a an√°lise de intelig√™ncia de mercado**, unindo raspagem de dados profundos, leitura de relat√≥rios em PDF e modelos de linguagem avan√ßados em uma √∫nica ferramenta. Tudo na tentantiva de ter insights aprimorados do mercado e me preparar para os movimentos da economia.

O objetivo √© simples: transformar dados brutos e n√£o estruturados em **insights acion√°veis**, ajudando a identificar tend√™ncias, movimentos da concorr√™ncia e padr√µes de mercado em tempo real.

O diferencial est√° na **modularidade**: voc√™ pode conectar qualquer provedor de IA (OpenAI, Azure, Gemini, Claude ou Hugging Face) e personalizar fontes e prompts com facilidade, tudo a partir de um √∫nico arquivo de configura√ß√£o.

---

## Principais Funcionalidades

- **Compat√≠vel com M√∫ltiplos Provedores de IA:**
  Plugue o modelo de linguagem da sua prefer√™ncia. Suporte nativo para:
  - Azure OpenAI
  - OpenAI (API padr√£o)
  - Google Gemini
  - Anthropic Claude
  - Hugging Face

- **An√°lise Profunda de PDFs:**
  Extrai o **conte√∫do completo** de relat√≥rios em formato PDF, permitindo que a IA analise os documentos na √≠ntegra, sem truncamento.

- **Raspagem de Artigos Completos:**
  N√£o se limita a manchetes; o sistema acessa os links de not√≠cias e extrai o **texto integral** dos artigos, fornecendo um contexto muito mais rico para a an√°lise.

- **Monitoramento de Tend√™ncias via Not√≠cias:**
  Utiliza o Google Not√≠cias para capturar as manchetes mais recentes sobre as palavras-chave, servindo como um term√¥metro em tempo real do interesse e da cobertura da m√≠dia sobre os temas.

- **Altamente Configur√°vel:**
  Palavras-chave, sites, prompts e provedor de IA podem ser ajustados facilmente no `config.py`, sem tocar na l√≥gica principal.

---

## Como Usar

### 1. Pr√©-requisitos

- Python 3.8 ou superior
- Git instalado
- Uma chave de API de um dos provedores suportados

---

### 2. Instala√ß√£o

Clone o reposit√≥rio:

```bash
git clone [https://github.com/rafa-rez/market_scrapper.git](https://github.com/rafa-rez/market_scrapper.git)
cd market_scrapper
```

Instale as depend√™ncias principais:

```bash
pip install requirements.txt
```

E depois, instale **somente** a biblioteca do provedor de IA que for usar:

| Provedor         | Comando de Instala√ß√£o             |
| ---------------- | --------------------------------- |
| Azure / OpenAI   | `pip install openai`              |
| Google Gemini    | `pip install google-generativeai` |
| Anthropic Claude | `pip install anthropic`           |
| Hugging Face     | `pip install huggingface-hub`     |

---

### 3. Configura√ß√£o

#### a. Arquivo `.env`

Crie um arquivo chamado `.env` na raiz do projeto e adicione **somente** as credenciais do provedor escolhido:

```env
# --- Azure OpenAI ---
AZURE_OPENAI_API_KEY="SUA_CHAVE_API"
AZURE_OPENAI_ENDPOINT="SEU_ENDPOINT"
AZURE_OPENAI_DEPLOYMENT="NOME_DO_SEU_DEPLOYMENT"

# --- OpenAI ---
OPENAI_API_KEY="sk-..."

# --- Google Gemini ---
GEMINI_API_KEY="..."

# --- Anthropic Claude ---
ANTHROPIC_API_KEY="..."

# --- Hugging Face ---
HUGGINGFACE_API_KEY="hf_..."
```

#### b. Configura√ß√£o da an√°lise (`config.py`)

Abra o `config.py` e ajuste os par√¢metros principais:

- `AI_PROVIDER`: provedor de IA em uso (`"gemini"`, `"openai"`, etc.)
- `KEYWORDS`: lista de palavras-chave a serem analisadas
- `NEWS_SITES`: sites de not√≠cias para extra√ß√£o de artigos completos
- `PDF_FOLDER`: pasta onde ficar√£o os arquivos PDF para an√°lise
- `SYSTEM_PROMPT` e `USER_PROMPT_TEMPLATE`: instru√ß√µes e o template de contexto para o modelo de IA.

#### c. Adicione seus arquivos PDF

Crie a pasta definida em `PDF_FOLDER` (ex: `reports/`) e coloque seus relat√≥rios `.pdf` nela.

---

### 4. Execu√ß√£o

Com tudo pronto, basta rodar:

```bash
python main.py
```

O script executa todas as etapas ‚Äî coleta, processamento e an√°lise ‚Äî e gera um arquivo `.txt` com os resultados na raiz do projeto.

---

## üìÅ Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ .env                     # Credenciais locais (n√£o versionado)
‚îú‚îÄ‚îÄ config.py                # Configura√ß√£o principal do projeto
‚îú‚îÄ‚îÄ main.py                  # Ponto de entrada da aplica√ß√£o
‚îú‚îÄ‚îÄ README.md                # Este mesmo arquivo
‚îî‚îÄ‚îÄ src/                     # C√≥digo-fonte principal
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ ai_client.py           # Comunica√ß√£o com diferentes APIs de IA
    ‚îú‚îÄ‚îÄ google_news_scraper.py # Captura de tend√™ncias via manchetes do Google Not√≠cias
    ‚îú‚îÄ‚îÄ news_scraper.py        # Coleta do conte√∫do completo de artigos
    ‚îî‚îÄ‚îÄ pdf_extractor.py       # Extra√ß√£o de texto de PDFs
```

---

## Futuras Melhorias

- **Cache Inteligente:** Implementar um sistema de cache para evitar reprocessar PDFs e artigos j√° analisados.
- **Execu√ß√£o Ass√≠ncrona:** Utilizar `asyncio` para acelerar drasticamente a etapa de scraping de not√≠cias.
- **CLI Interativa:** Adicionar argumentos de linha de comando (`argparse`) para passar palavras-chave e configura√ß√µes sem editar o c√≥digo.
- **Estrat√©gia "Summarize-then-Synthesize":** Reduzir custos e aumentar a precis√£o ao primeiro resumir cada documento individualmente antes da an√°lise final.
- **Relat√≥rios Estruturados:** Gerar sa√≠das em Markdown ou JSON em vez de `.txt`.

Se curtiu o projeto, sinta-se √† vontade para **contribuir, testar ou sugerir novas ideias**.

---

<p align="center">
    <em>‚ÄúTalk is cheap. Show me the code.‚Äù</em><br>
  ‚Äî <strong>Linus Torvalds</strong>
</p>